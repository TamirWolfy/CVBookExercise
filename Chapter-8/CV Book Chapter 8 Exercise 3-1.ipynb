{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from PIL import *\n",
    "import pickle\n",
    "from pylab import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sift\n",
    "import dsift\n",
    "dsift = reload(dsift)\n",
    "import imtools\n",
    "imtools = reload(imtools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_gesture_features_labels(path):\n",
    "    # make a list of the files with .dsift at the end\n",
    "    featlist = [os.path.join(path, f) for f in os.listdir(path)\n",
    "               if f.endswith('.dsift')]\n",
    "    \n",
    "    # read features\n",
    "    features = []\n",
    "    for featfile in featlist:\n",
    "        l, d = sift.read_features_from_file(featfile)\n",
    "        features.append(d.flatten())\n",
    "    features = array(features)\n",
    "    \n",
    "    # generate labels\n",
    "    labels = [featfile.split('/')[-1][0] for featfile in featlist]\n",
    "    \n",
    "    return features, array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = read_gesture_features_labels('train2/')\n",
    "test_features, test_labels = read_gesture_features_labels('test2/')\n",
    "classnames = unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V' 'A' 'A' 'B' 'P' 'B' 'P' 'C' 'F' 'A' 'P' 'V' 'F' 'F' 'P' 'B' 'P' 'F'\n",
      " 'F' 'B' 'P' 'F' 'F' 'A' 'F' 'P' 'A' 'A' 'F' 'V' 'A' 'P' 'V' 'V' 'P' 'A'\n",
      " 'P' 'C' 'B' 'B' 'C' 'P' 'C' 'V' 'P' 'V' 'V' 'C' 'B' 'C' 'V' 'P' 'P' 'B'\n",
      " 'B' 'C' 'A' 'C' 'V' 'B' 'V' 'B' 'F' 'P' 'A' 'P' 'B' 'P' 'B' 'V' 'F' 'B'\n",
      " 'C' 'A' 'C' 'C' 'F' 'F' 'V' 'P' 'C' 'F' 'P' 'A' 'A' 'F' 'P' 'B' 'A' 'V'\n",
      " 'F' 'V' 'C' 'C' 'B' 'C' 'A' 'F' 'F' 'A' 'V' 'C' 'V' 'V' 'A' 'B' 'A' 'C'\n",
      " 'B' 'C' 'B' 'B' 'V' 'A' 'C' 'V' 'C' 'F' 'C' 'F' 'F' 'P' 'A' 'B' 'P' 'P'\n",
      " 'B' 'B' 'A' 'F' 'B' 'A' 'C' 'C' 'V' 'A' 'C' 'P' 'P' 'V' 'F' 'V' 'P' 'A'\n",
      " 'F' 'A' 'V' 'F' 'F' 'C' 'C' 'B' 'V' 'P' 'B' 'V' 'P' 'V' 'A' 'C' 'V' 'A'\n",
      " 'V' 'A' 'F' 'F' 'B' 'A' 'B' 'F' 'C' 'B' 'C' 'P']\n"
     ]
    }
   ],
   "source": [
    "# the first letter of the file name is the label\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k neighbors\n",
    "k = 1\n",
    "knn_classifier = knn.KnnClassifier(labels, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.242718446602\n"
     ]
    }
   ],
   "source": [
    "res = array([knn_classifier.classify(test_features[i], k) for i in\n",
    "            range(len(test_labels))])\n",
    "\n",
    "# accuracy\n",
    "acc = sum(1.0*(res==test_labels))/len(test_labels)\n",
    "print 'Accuracy:', acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is lower than the number in the text book (0.811518324607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion(res, test_labels, classnames):\n",
    "    \n",
    "    n = len(classnames)\n",
    "    \n",
    "    class_ind = dict([(classnames[i], i) for i in range(n)])\n",
    "    \n",
    "    confuse = zeros((n, n))\n",
    "    for i in range(len(test_labels)):\n",
    "        confuse[class_ind[res[i]], class_ind[test_labels[i]]] += 1\n",
    "    \n",
    "    print 'Confusion matrix for'\n",
    "    print classnames\n",
    "    print confuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for\n",
      "['A' 'B' 'C' 'F' 'P' 'V']\n",
      "[[  1.   0.   2.   2.   0.   0.]\n",
      " [  2.   5.   0.  10.   7.   5.]\n",
      " [  2.   0.   7.   1.   1.   0.]\n",
      " [  1.   3.   1.   6.   0.   0.]\n",
      " [  0.   0.   4.   0.   2.   0.]\n",
      " [  4.   4.   4.  10.  15.   4.]]\n"
     ]
    }
   ],
   "source": [
    "print_confusion(res, test_labels, classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V, S, m = pca.pca(array(features))\n",
    "V = V[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features2 = [dot(V, f-m) for f in features]\n",
    "test_features2 = [dot(V, f-m) for f in test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_classifier2 = knn.KnnClassifier(labels, features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.271844660194\n"
     ]
    }
   ],
   "source": [
    "res2 = array([knn_classifier2.classify(test_features2[i], k) for i in\n",
    "            range(len(test_labels))])\n",
    "\n",
    "# accuracy\n",
    "acc2 = sum(1.0*(res2==test_labels))/len(test_labels)\n",
    "print 'Accuracy:', acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for\n",
      "['A' 'B' 'C' 'F' 'P' 'V']\n",
      "[[  1.   0.   1.   2.   0.   0.]\n",
      " [  2.   6.   0.  10.   6.   4.]\n",
      " [  2.   0.   8.   0.   0.   0.]\n",
      " [  1.   3.   1.   6.   0.   0.]\n",
      " [  0.   0.   4.   0.   2.   0.]\n",
      " [  4.   3.   4.  11.  17.   5.]]\n"
     ]
    }
   ],
   "source": [
    "print_confusion(res2, test_labels, classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Around 50-100 seems to be the sweet spot. Just before the curve in figure 8-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
